{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d20010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "import pandas as pd\n",
    "\n",
    "import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dbdb5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "70012629-e5e7-426d-815d-d49db0e84cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 39\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_excel(\"reddit-comments-eval.xlsx\")\n",
    "print(f\"Number of rows: {data.shape[0]}\")\n",
    "\n",
    "error_columns = ['keywords-node', 'tool-node', 'tone-summary-node', 'reply-node']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "0bff37f8-c337-4866-96aa-f8c4067dc723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 17)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[~data['keywords-node'].isna()]\n",
    "data.shape\n",
    "# data[error_columns] = data[error_columns].astype(int).astype(bool)\n",
    "\n",
    "# data[error_columns].head()\n",
    "\n",
    "# data['no_errors'] = data[error_columns].all(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "00711f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import operator\n",
    "from typing import Annotated, List, Optional, TypedDict, Sequence\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "logger = logging.getLogger(\"reddit-comments\")\n",
    "\n",
    "class State(TypedDict):\n",
    "    batch_id: str\n",
    "    input: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    output: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "df5924a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "llm = ChatAnthropic(model='claude-3-5-sonnet-20240620')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a2cf46c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_llm_performance(state: State):\n",
    "    batch_id = state[\"batch_id\"][-1]\n",
    "    input = state['input'][-1]\n",
    "    output = state['output'][-1]\n",
    "\n",
    "    prompt = f\"\"\"You are a validator who is diligent and careful. When things are incorrect, you call it out and nothing gets past you.\n",
    "    Given a input and ouput, your goal is to check if the output followed the directions in the input.\n",
    "\n",
    "    Special instructions: \n",
    "    1. If the input task was to format something as a python list of strings, you can ignore that. \n",
    "    2. If the task is to extract two words, and more words have been extracted, ignore that. That output is correct.\n",
    "    3. If there is a word-limit, you can ignore that as well as long as the output is close to the requested word limit.\n",
    "\n",
    "    Analyze and output in JSON format with keys: \"reason\" (the reason why this is correct or incorrect), \"check\" (1 for correct and 0 for incorrect)\n",
    "    \n",
    "    Please, absolutely no preamble in the response, just a json output. You'll be penalized otherwise.\n",
    "\n",
    "    Input: {input}\n",
    "    Output: {output}\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"batch_id\": batch_id,\"input\": [input], \"output\":[output], \"messages\": [response.content]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "af042a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, Graph, START, END\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"validate_llm_performance\", validate_llm_performance)\n",
    "\n",
    "workflow.add_edge(START, \"validate_llm_performance\")\n",
    "workflow.add_edge(\"validate_llm_performance\", END)\n",
    "\n",
    "graph = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3cbfa0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "25b317f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 31\n",
    "end = 40\n",
    "\n",
    "mappings = [\n",
    "    ('prompt-1', 'output-keywords'),\n",
    "    ('prompt-2', 'output-article_search'),\n",
    "    ('prompt-3', 'output-replies'),\n",
    "    ('prompt-4', 'output-reply')\n",
    "    ]\n",
    "\n",
    "llm_evals_of_entire_posts = {}\n",
    "for index, row in data[start:end].iterrows():\n",
    "    # Cycle through each post's input and outputs.\n",
    "    # Each post has 4 prompts and 4 outputs\n",
    "    json_data = row.to_dict()\n",
    "    batch_id = json_data['post_id']\n",
    "\n",
    "    # Cycle through each input/output prompt/response generated by the LLM and evaluate it\n",
    "    input_output_evaluation = []\n",
    "    for prompt_key, output_key in mappings:\n",
    "        prompt_text = json_data.get(prompt_key, None)\n",
    "        output_text = json_data.get(output_key, None)\n",
    "        evaluation_response = graph.invoke({\"batch_id\": [batch_id], \"input\": [prompt_text], \"output\": [output_text]})\n",
    "        input_output_evaluation.append(evaluation_response)\n",
    "\n",
    "    llm_evals_of_entire_posts[batch_id] = input_output_evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "bc167791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(post_id, post_evaluation):\n",
    "    previous_responses = pd.read_excel(\"llm-evals.xlsx\", sheet_name=\"Sheet1\")\n",
    "\n",
    "    checks = {f\"check-{idx+1}\": json.loads(r['messages'][0])['check'] for idx, r in enumerate(post_evaluation)}\n",
    "    reasons = {f\"reason-{idx+1}\": json.loads(r['messages'][0])['reason'] for idx, r in enumerate(post_evaluation)}\n",
    "    inputs = {f\"input-{idx+1}\": r[\"input\"][0] for idx, r in enumerate(post_evaluation)}\n",
    "    outputs = {f\"output-{idx+1}\": r[\"output\"][0] for idx, r in enumerate(post_evaluation)}\n",
    "\n",
    "    checks_pd = pd.DataFrame([{**inputs, **outputs, **checks, **reasons}])  \n",
    "    checks_pd['batch_id'] = post_id \n",
    "\n",
    "    updated_responses = pd.concat([previous_responses, checks_pd])\n",
    "    updated_responses.to_excel(\"llm-evals.xlsx\", sheet_name=\"Sheet1\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "04776d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for post_id, post_evaluation in llm_evals_of_entire_posts.items():\n",
    "    try:\n",
    "        write_to_file(post_id, post_evaluation)\n",
    "    except Exception as e:\n",
    "        print(post_id, e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5873fc19",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "f2830615",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_llm_outputs = pd.read_excel(\"llm-evals.xlsx\")\n",
    "data_llm_outputs.rename(columns={\n",
    "    \"check-1\": \"keywords-node\",\n",
    "    \"check-2\": \"tool-node\",\n",
    "    \"check-3\": \"tone-summary-node\",\n",
    "    \"check-4\": \"reply-node\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "5c568a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.parents = []\n",
    "\n",
    "    def add_parent(self, parent):\n",
    "        self.parents.append(parent)\n",
    "    \n",
    "def create_graph():\n",
    "    nodes = {\n",
    "        \"keywords-node\": Node(\"keywords-node\"),\n",
    "        \"tool-node\": Node(\"tool-node\"),\n",
    "        \"tone-summary-node\": Node(\"tone-summary-node\"),\n",
    "        \"reply-node\": Node(\"reply-node\")\n",
    "    }\n",
    "\n",
    "    nodes['reply-node'].add_parent(nodes['tone-summary-node'])\n",
    "    nodes['tone-summary-node'].add_parent(nodes['tool-node'])\n",
    "    nodes['tool-node'].add_parent(nodes['keywords-node'])\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "ddf3792e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keywords-node': <__main__.Node at 0x16cd5d970>,\n",
       " 'tool-node': <__main__.Node at 0x16cd5da30>,\n",
       " 'tone-summary-node': <__main__.Node at 0x16cd5dd90>,\n",
       " 'reply-node': <__main__.Node at 0x16cd5d310>}"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_graph = create_graph()\n",
    "analysis_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "3edd68e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing node: reply-node\n",
      "Overall failure probability for this node: 0.1290\n",
      "Independent failure probability: 0.1333\n",
      "Node failure because dep fails: 0.0\n",
      "Conditional failure probabilities given upstream dependency failures:\n",
      "  P(reply-node fails | tone-summary-node fails): 0.0000\n",
      "\n",
      "\n",
      "Root cause analysis complete.\n",
      "Debug path (from downstream to upstream): reply-node\n",
      "Most likely root cause (most upstream issue): reply-node\n",
      "Independent failure probability of root cause: 0.1333\n",
      "Conditional failure probabilities given root cause's dependency failures:\n",
      "  P(reply-node fails | tone-summary-node fails): 0.0000\n",
      "\n",
      "The most likely cause is an independent failure in node reply-node\n",
      "Focus on node: (['reply-node'], 0.13333333333333333, {'tone-summary-node': 0.0})\n"
     ]
    }
   ],
   "source": [
    "# Rewritten code\n",
    "\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def calculate_probabilities(node: str, data: pd.DataFrame, dependencies: List[Node]) -> Tuple[float, Dict[str, float]]:\n",
    "    \"\"\"Calculate failure probabilities for the node and its upstream dependencies.\"\"\"\n",
    "    node_fails = data[node] == False\n",
    "    p_node_fails = node_fails.mean()\n",
    "    \n",
    "    # Calculate independent failure probability\n",
    "    if not dependencies:\n",
    "        p_independent_fail = p_node_fails\n",
    "    else:\n",
    "        deps_pass = data[[dep.name for dep in dependencies]].all(axis=1)\n",
    "        p_independent_fail = (node_fails & deps_pass).sum() / deps_pass.sum()\n",
    "    \n",
    "    # Calculate conditional failure probabilities for dependencies\n",
    "    p_node_fails_given_dep_fails = {}\n",
    "    for dep in dependencies:\n",
    "        dep_fails = data[dep.name] == False\n",
    "\n",
    "        p_node_fails_given_dep_fails[dep.name] = (node_fails & dep_fails).sum() / dep_fails.sum() if dep_fails.sum() != 0 else 0\n",
    "\n",
    "        \n",
    "    return p_node_fails, p_independent_fail, p_node_fails_given_dep_fails\n",
    "\n",
    "def find_root_cause(node: str, data: pd.DataFrame, graph: Dict[str, Node]) -> Tuple[List[str], float, Dict[str, float]]:\n",
    "    \"\"\"Recursively find the root cause of failures, tracing from downstream to upstream.\"\"\"\n",
    "    dependencies = graph[node].parents  # These are upstream nodes\n",
    "\n",
    "    p_node_fails, p_independent_fail, p_node_fails_given_dep_fails = calculate_probabilities(node, data, dependencies)\n",
    "    \n",
    "    print(f\"Analyzing node: {node}\")\n",
    "    print(f\"Overall failure probability for this node: {p_node_fails:.4f}\")\n",
    "    print(f\"Independent failure probability: {p_independent_fail:.4f}\")\n",
    "    print(f\"Node failure because dep fails: {max([v for _, v in p_node_fails_given_dep_fails.items()])}\")\n",
    "    print(f\"Conditional failure probabilities given upstream dependency failures:\")\n",
    "    for dep, prob in p_node_fails_given_dep_fails.items():\n",
    "        print(f\"  P({node} fails | {dep} fails): {prob:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    # Check if independent failure is more likely than any upstream dependency failure\n",
    "    if p_independent_fail > max(p_node_fails_given_dep_fails.values(), default=0) :\n",
    "        return [node], p_independent_fail, p_node_fails_given_dep_fails\n",
    "\n",
    "    if not dependencies:\n",
    "        return [node], p_independent_fail, p_node_fails_given_dep_fails\n",
    "\n",
    "    max_dep = max(p_node_fails_given_dep_fails, key=p_node_fails_given_dep_fails.get)\n",
    "    upstream_path, upstream_independent_prob, upstream_final_probs = find_root_cause(max_dep, data, graph)\n",
    "    \n",
    "    return [node] + upstream_path, upstream_independent_prob, upstream_final_probs\n",
    "\n",
    "def improve_system(downstream_node: str, data: pd.DataFrame, graph: Dict[str, Node]) -> Tuple[List[str], float, Dict[str, float]]:\n",
    "    \"\"\"Entry point for the root cause analysis, starting from the most downstream node.\"\"\"\n",
    "    path, independent_prob, final_probs = find_root_cause(downstream_node, data, graph)\n",
    "    \n",
    "    print(\"\\nRoot cause analysis complete.\")\n",
    "    print(f\"Debug path (from downstream to upstream): {' -> '.join(path)}\")\n",
    "    print(f\"Most likely root cause (most upstream issue): {path[-1]}\")\n",
    "    print(f\"Independent failure probability of root cause: {independent_prob:.4f}\")\n",
    "    print(\"Conditional failure probabilities given root cause's dependency failures:\")\n",
    "    for dep, prob in final_probs.items():\n",
    "        print(f\"  P({path[-1]} fails | {dep} fails): {prob:.4f}\")\n",
    "    \n",
    "    if independent_prob > max(final_probs.values(), default=0):\n",
    "        print()\n",
    "        print(f\"The most likely cause is an independent failure in node {path[-1]}\")\n",
    "    else:\n",
    "        most_likely_dep = max(final_probs.values(), default=0)\n",
    "        print()\n",
    "        print(f\"The most likely cause is a failure in dependency: {most_likely_dep}\")\n",
    "    \n",
    "    return path, independent_prob, final_probs\n",
    "\n",
    "print()\n",
    "print(f\"Focus on node: {improve_system('reply-node', data=data_llm_outputs, graph=analysis_graph)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d24abd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
